import express from 'express';
import cors from 'cors';
import { GoogleGenerativeAI } from '@google/generative-ai';
import 'dotenv/config';

const app = express();
const port = 3000;

app.use(cors());
app.use(express.json());

const API_KEY = process.env.GEMINI_API_KEY;

if (!API_KEY) {
  console.error("âŒ è‡´å‘½é”™è¯¯ï¼šæœªæ‰¾åˆ° API Keyã€‚");
  process.exit(1);
}

const genAI = new GoogleGenerativeAI(API_KEY);

const MODEL_MAIN = "gemini-2.5-flash";
const MODEL_BACKUP = "gemini-1.5-flash";

// ğŸ›¡ï¸ æ™ºèƒ½ JSON æå–å™¨
function extractJSON(str) {
  let startIndex = str.indexOf('{');
  if (startIndex === -1) return null;
  
  let braceCount = 0;
  let endIndex = -1;
  
  for (let i = startIndex; i < str.length; i++) {
    if (str[i] === '{') {
      braceCount++;
    } else if (str[i] === '}') {
      braceCount--;
      if (braceCount === 0) {
        endIndex = i;
        break;
      }
    }
  }
  
  if (endIndex !== -1) {
    return str.substring(startIndex, endIndex + 1);
  }
  return null;
}

// åŸºç¡€ç”Ÿæˆå‡½æ•°
async function generateOnce(modelName, prompt) {
    const model = genAI.getGenerativeModel({ 
        model: modelName,
        generationConfig: {
            temperature: 0.4, // ç¨å¾®é™ä½éšæœºæ€§ï¼Œä¿è¯æ ¼å¼ç¨³å®š
            topP: 0.8,
            topK: 40,
        }
    });
    const result = await model.generateContent(prompt);
    return result.response.text();
}

// æ™ºèƒ½é™çº§ç­–ç•¥
async function generateSmartResponse(prompt) {
    const maxRetriesMain = 4;
    for (let i = 0; i < maxRetriesMain; i++) {
        try {
            console.log(`ğŸš€ [ä¸»åŠ›] å°è¯•è°ƒç”¨ ${MODEL_MAIN} (ç¬¬ ${i + 1}/${maxRetriesMain} æ¬¡)...`);
            const text = await generateOnce(MODEL_MAIN, prompt);
            return { text, modelUsed: MODEL_MAIN };
        } catch (error) {
            const isOverloaded = error.message.includes('503') || error.message.includes('overloaded');
            console.warn(`âš ï¸ [ä¸»åŠ›] ${MODEL_MAIN} å¤±è´¥: ${error.message}`);
            if (i < maxRetriesMain - 1) {
                const delay = 2000 * Math.pow(2, i);
                await new Promise(r => setTimeout(r, delay));
            }
        }
    }

    const maxRetriesBackup = 2;
    for (let i = 0; i < maxRetriesBackup; i++) {
        try {
            console.log(`ğŸ›¡ï¸ [æ›¿è¡¥] æ­£åœ¨åˆ‡æ¢è‡³ ${MODEL_BACKUP} (ç¬¬ ${i + 1}/${maxRetriesBackup} æ¬¡)...`);
            const text = await generateOnce(MODEL_BACKUP, prompt);
            return { text, modelUsed: MODEL_BACKUP };
        } catch (error) {
            console.error(`âŒ [æ›¿è¡¥] ${MODEL_BACKUP} ä¹Ÿå¤±è´¥äº†`);
            if (i < maxRetriesBackup - 1) await new Promise(r => setTimeout(r, 2000));
        }
    }
    throw new Error("æ‰€æœ‰ AI æ¨¡å‹ï¼ˆä¸»åŠ›+æ›¿è¡¥ï¼‰å‡ä¸å¯ç”¨ï¼Œè¯·ç¨åå†è¯•ã€‚");
}

// å…«å­—åˆ†ææ¥å£
app.post('/api/analyze', async (req, res) => {
  try {
    const { chart, currentYear } = req.body; 
    const daYunStr = chart?.daYun ? chart.daYun.map(d => d.ganZhi).join(',') : "æš‚æ— ";
    const balanceStr = chart?.balanceNote ? chart.balanceNote.join(', ') : "äº”è¡Œå¹³è¡¡";
    const lingShu = chart?.lingShu || { lifePathNumber: 0 };

    // ğŸ”¥ å¢å¼ºç‰ˆ Promptï¼šå¼ºåˆ¶ 5 äººï¼Œå¼ºåˆ¶æ·±åº¦ï¼Œå¼ºåˆ¶å¤ç±
    const prompt = `
      ã€è§’è‰²è®¾å®šã€‘
      ä½ æ˜¯ä¸€ä½ç²¾é€šã€Šä¸‰å‘½é€šä¼šã€‹ã€ã€Šç©·é€šå®é‰´ã€‹çš„èµ„æ·±å‘½ç†å¤§å¸ˆã€‚ä½ çš„é£æ ¼æ˜¯**æ·±åº¦ã€è¯¦å°½ã€å¼•ç»æ®å…¸**ã€‚
      
      ã€è¯­è¨€è¦æ±‚ã€‘
      1. å…¨ç¨‹ä½¿ç”¨**ç®€ä½“ä¸­æ–‡**ã€‚
      2. é™¤éæ˜¯ä¸“æœ‰åè¯ï¼Œå¦åˆ™ä¸è¦å‡ºç°è‹±æ–‡ã€‚

      ã€åˆ†æå¯¹è±¡ã€‘
      å…«å­—: ${chart.year.stem}${chart.year.branch} ${chart.month.stem}${chart.month.branch} ${chart.day.stem}${chart.day.branch} ${chart.hour.stem}${chart.hour.branch}
      æ—¥ä¸»: ${chart.dayMaster} æ ¼å±€: ${chart.strength}
      å¤§è¿: ${daYunStr}
      äº”è¡Œè¯Šæ–­: ${balanceStr}
      çµæ•°å‘½æ•°: ${lingShu.lifePathNumber}

      ã€è¾“å‡ºä»»åŠ¡ (å¿…é¡»ä¸¥æ ¼éµå¾ªæ­¤JSONæ ¼å¼ï¼Œä¸è¦Markdown)ã€‘
      {
        "archetype": "å‘½æ ¼èµå(4å­—, å¦‚é‡‘æ°´ç›¸æ¶µ)",
        "summary": "30å­—ç²¾è¯„(ä¸€é’ˆè§è¡€)",
        "appearanceAnalysis": "å®¹è²Œæ°”è´¨æè¿°(åŸºäºäº”è¡Œ/éº»è¡£ç¥ç›¸, 100å­—)",
        "annualLuckAnalysis": "${currentYear}å¹´æµå¹´è¿åŠ¿(ç»“åˆå¤§è¿, è¯¦ç»†åˆ†æäº‹ä¸šã€è´¢è¿ã€æ„Ÿæƒ…å˜åŒ–)",
        
        "historicalFigures": [
            {"name": "åäºº1", "similarity": "ç›¸ä¼¼åº¦", "reason": "å¯¹æ¯”åˆ†æ"},
            {"name": "åäºº2", "similarity": "ç›¸ä¼¼åº¦", "reason": "å¯¹æ¯”åˆ†æ"},
            {"name": "åäºº3", "similarity": "ç›¸ä¼¼åº¦", "reason": "å¯¹æ¯”åˆ†æ"},
            {"name": "åäºº4", "similarity": "ç›¸ä¼¼åº¦", "reason": "å¯¹æ¯”åˆ†æ"},
            {"name": "åäºº5", "similarity": "ç›¸ä¼¼åº¦", "reason": "å¯¹æ¯”åˆ†æ"}
        ],
        // âš ï¸ å¿…é¡»åˆ—å‡º 5 ä½ï¼å°‘äº 5 ä½è§†ä¸ºå¤±è´¥ã€‚
        
        "strengthAnalysis": "æ ¼å±€æ·±åº¦è§£æã€‚è¯¦ç»†åˆ†ææ—¥ä¸»å¼ºå¼±ã€å–œç”¨ç¥ã€æ ¼å±€é«˜ä½ã€‚å­—æ•°ä¸å°‘äº300å­—ï¼Œè¦æœ‰æ·±åº¦ã€‚",
        
        "bookAdvice": "å¤ç±å»ºè®®(å¿…é¡»å¼•ç”¨ã€Šç©·é€šå®é‰´ã€‹æˆ–ã€Šä¸‰å‘½é€šä¼šã€‹çš„åŸæ–‡)",
        "bookAdviceTranslation": "å¤æ–‡çš„ç™½è¯æ–‡æ·±åº¦è§£æ(ä¸ä»…ä»…æ˜¯ç¿»è¯‘ï¼Œè¦æœ‰ç»“åˆå‘½ä¸»çš„è§£è¯»)",
        
        "careerAdvice": "äº‹ä¸šå‘å±•å»ºè®®(å…·ä½“åˆ°è¡Œä¸šå’ŒèŒèƒ½)",
        "healthAdvice": "å¥åº·ç®¡ç†å»ºè®®",
        
        "numerologyAnalysis": "çµæ•°${lingShu.lifePathNumber}æ·±åº¦è§£è¯»ï¼šåŒ…å«æ€§æ ¼ä¼˜åŠ¿ã€æ½œåœ¨æŒ‘æˆ˜ã€äººç”Ÿä½¿å‘½ã€‚"
      }
    `;

    console.log("æ­£åœ¨è¯·æ±‚ AI (å…«å­—æ·±åº¦ç‰ˆ)...");
    const { text, modelUsed } = await generateSmartResponse(prompt);
    
    const jsonStr = extractJSON(text);
    if (!jsonStr) throw new Error(`AI (${modelUsed}) è¿”å›æ•°æ®æ ¼å¼å¼‚å¸¸`);

    const data = JSON.parse(jsonStr);
    res.set('X-Model-Used', modelUsed);
    res.json(data);

  } catch (error) {
    console.error("API é”™è¯¯:", error.message);
    res.status(503).json({ error: "åˆ†ææœåŠ¡ç¹å¿™ï¼Œæ­£åœ¨ä¸ºæ‚¨æ’é˜Ÿï¼Œè¯·ç¨åå†è¯•ï¼" });
  }
});

// å¥‡é—¨å†³ç­–æ¥å£
app.post('/api/qimen', async (req, res) => {
  try {
    const { type, context, result } = req.body; 
    const signalMap = { 'green': 'ğŸŸ¢ å¯è¡ŒåŠ¨', 'yellow': 'ğŸŸ¡ éœ€è§‚å¯Ÿ', 'red': 'ğŸ”´ ä¸å»ºè®®' };
    const prompt = `
      è§’è‰²ï¼šå¥‡é—¨å†³ç­–é¡¾é—®ã€‚è¯­è¨€ï¼šç®€ä½“ä¸­æ–‡ã€‚
      é—®é¢˜ï¼š${type} èƒŒæ™¯ï¼š${context || "æ— "}
      ä¿¡å·ï¼š${signalMap[result.signal]} åˆ¤è¯ï¼š${result.summary} å› å­ï¼š${result.factors.join(', ')}
      è¾“å‡ºJSON: { "mainTendency": "æ ¸å¿ƒåˆ¤æ–­", "reasoning": ["åŸå› 1", "åŸå› 2"], "actionAdvice": "è¡ŒåŠ¨å»ºè®®", "riskAlert": "é£é™©æç¤º" }
    `;
    
    const { text, modelUsed } = await generateSmartResponse(prompt);
    const jsonStr = extractJSON(text);
    if (!jsonStr) throw new Error(`AI (${modelUsed}) æ ¼å¼å¼‚å¸¸`);
    res.set('X-Model-Used', modelUsed).json(JSON.parse(jsonStr));

  } catch (error) {
    res.status(503).json({ error: "å†³ç­–æœåŠ¡ç¹å¿™ï¼Œè¯·ç¨åå†è¯•ã€‚" });
  }
});

app.listen(port, () => {
  console.log(`âœ… åç«¯æœåŠ¡å™¨å·²å¯åŠ¨: http://localhost:${port}`);
  console.log(`   - ä¸»åŠ›: ${MODEL_MAIN} | æ›¿è¡¥: ${MODEL_BACKUP}`);
});